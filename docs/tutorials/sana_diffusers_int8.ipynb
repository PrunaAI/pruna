{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#  x2 smaller Sana in action"
            ]
        },
        {
            "cell_type": "raw",
            "metadata": {
                "vscode": {
                    "languageId": "raw"
                }
            },
            "source": [
                "<a target=\"_blank\" href=\"https://colab.research.google.com/github/PrunaAI/pruna/blob/v|version|/docs/tutorials/sana_diffusers_int8.ipynb\">\n",
                "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
                "</a>"
            ]
        },
        {
            "cell_type": "raw",
            "metadata": {
                "raw_mimetype": "text/restructuredtext",
                "vscode": {
                    "languageId": "raw"
                }
            },
            "source": [
                "This tutorial demonstrates how to use the ``pruna`` package to optimize the memory footprint (going from 16 bits to 8 bits) of any diffusion model from the diffusers package.\n",
                "We will use the ``Sana_600M_512px`` model as an example, but this tutorial is working on any stable diffusion or flux model.\n",
                "Have a look at the ``pruna_pro`` tutorial :doc:`\"Shrink and accelerate Sana diffusion x4 smaller and x2 faster\" </docs_pruna_pro/tutorials/sana_torchao_autoquant>`, if you want a x2 speedup."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# if you are not running the latest version of this tutorial, make sure to install the matching version of pruna\n",
                "# the following command will install the latest version of pruna\n",
                "%pip install pruna"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Loading the Diffusion Model\n",
                "\n",
                "First, load your diffusion model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from diffusers import SanaPipeline\n",
                "\n",
                "# Define the model ID\n",
                "model_id = \"Efficient-Large-Model/Sana_600M_512px_diffusers\"\n",
                "\n",
                "# Load the pre-trained model\n",
                "pipe = SanaPipeline.from_pretrained(model_id, variant=\"fp16\", torch_dtype=torch.float16)\n",
                "pipe = pipe.to(\"cuda\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Initializing the Smash Config"
            ]
        },
        {
            "cell_type": "raw",
            "metadata": {
                "raw_mimetype": "text/restructuredtext",
                "vscode": {
                    "languageId": "raw"
                }
            },
            "source": [
                "Next, initialize the smash_config (we make use, here, of the :doc:`bitsandbytes </compression>` quantization algorithm)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pruna import SmashConfig\n",
                "\n",
                "# Initialize the SmashConfig\n",
                "smash_config = SmashConfig()\n",
                "smash_config['quantizer'] = 'hqq_diffusers'\n",
                "smash_config['hqq_diffusers_weight_bits'] = 8"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Smashing the Model\n",
                "\n",
                "Now, smash the model. This can take up to 30 seconds."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pruna import smash\n",
                "\n",
                "# Smash the model\n",
                "smashed_model = smash(\n",
                "    model=pipe,\n",
                "    smash_config=smash_config,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Running the Model\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Finally, run the model to generate the image."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define the prompt\n",
                "prompt = \"a smiling cat dancing on a table. Miyazaki style\"\n",
                "\n",
                "# Display the result\n",
                "smashed_model(prompt).images[0]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Wrap Up"
            ]
        },
        {
            "cell_type": "raw",
            "metadata": {
                "raw_mimetype": "text/restructuredtext",
                "vscode": {
                    "languageId": "raw"
                }
            },
            "source": [
                "Congratulations! You have successfully smashed a Sana model! You can now use the ``pruna`` package to optimize any custom diffusion model. The only parts that you should modify are step 1 and step 4 to fit your use case.\n",
                "Is it not enough? You can check this ``pruna_pro`` tutorial :doc:`\"Shrink and accelerate Sana diffusion x4 smaller and x2 faster\" </docs_pruna_pro/tutorials/sana_torchao_autoquant>` to go one step further and also take advantage of accelerated inference!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "prunatree",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
