{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing and Deploying AI Models with Pruna and Hugging Face\n",
    "\n",
    "Objective: Build a complete tutorial demonstrating how to optimize the [Efficient-Large-Model/Sana_600M_1024px_ControlNet_HED](https://huggingface.co/Efficient-Large-Model/Sana_600M_1024px_ControlNet_HED) diffusion model using Pruna and deploy it seamlessly to the Hugging Face Hub.\n",
    "\n",
    "Model: [Efficient-Large-Model/Sana_600M_1024px_ControlNet_HED](https://huggingface.co/Efficient-Large-Model/Sana_600M_1024px_ControlNet_HED)\n",
    "\n",
    "Dataset: [data-is-better-together/open-image-preferences-v1-binarized](https://huggingface.co/datasets/data-is-better-together/open-image-preferences-v1-binarized)\n",
    "\n",
    "To follow along, ensure that you have the Pruna SDK installed along with all required third-party libraries. Running this tutorial in a clean virtual environment is recommended for a smooth setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pruna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install datasets huggingface_hub gradio diffusers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to login on the Hugging Face Hub for using the model weights. Run the cell below to do the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cddba2c14fe4f0fa3761154584ebc9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smash Configuration\n",
    "\n",
    "To optimize the model, we first need to define the methods that will enhance its performance. For detailed options, refer to the [SmashConfig guide](https://docs.pruna.ai/en/stable/docs_pruna/user_manual/configure.html).\n",
    "\n",
    "In this tutorial, we will:\n",
    "\n",
    "* Select a **quantizer** to reduce memory usage\n",
    "* Use a **cacher** to store intermediate computation results, accelerating future operations\n",
    "* Upload the optimized (smashed) model to the Hugging Face Hub for easy access and deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pruna import smash, SmashConfig, PrunaModel\n",
    "from diffusers import SanaPipeline\n",
    "\n",
    "# Define the model ID\n",
    "model_id = \"Efficient-Large-Model/Sana_600M_512px_diffusers\"\n",
    "\n",
    "# Load the pre-trained model\n",
    "pipe = SanaPipeline.from_pretrained(model_id, variant=\"fp16\", torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "# 2. Configure Pruna smash\n",
    "smash_config = SmashConfig()\n",
    "smash_config[\"quantizer\"] = \"hqq_diffusers\"  # Quantizer to reduce memory usage\n",
    "smash_config['hqq_diffusers_weight_bits'] = 8          # Cacher to speed up computations\n",
    "\n",
    "# 3. Smash (optimize) the model\n",
    "smashed_pipe = smash(model=pipe, smash_config=smash_config)\n",
    "\n",
    "# 4. Push the smashed pipeline to Hugging Face Hub using save_to_hub\n",
    "smashed_pipe.save_to_hub(\"AINovice2005/Sana_600M_ControlNet_HED-smashed\")\n",
    "\n",
    "print(\"✅ Smashed Sana model uploaded successfully to Hugging Face Hub.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset and Collate Dataset\n",
    "\n",
    "In this step, we will load the dataset required for optimizing and evaluating the model. This dataset will serve as input data during the evaluation and help assess the model’s performance after applying quantization.\n",
    "\n",
    "We will use the [`data-is-better-together/open-image-preferences-v1-binarized`](https://huggingface.co/datasets/data-is-better-together/open-image-preferences-v1-binarized) dataset, which contains binarized user image preferences. Loading the dataset correctly ensures that the input pipeline is ready for smooth optimization and deployment workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'datasets' has no attribute 'utils' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset  \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpruna\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpruna_datamodule\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PrunaDataModule  \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpruna\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m split_train_into_train_val_test  \n",
      "File \u001b[0;32m~/test_env/lib/python3.9/site-packages/datasets/__init__.py:26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfingerprint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m disable_caching, enable_caching, is_caching_enabled\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DatasetInfo\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspect\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m     get_dataset_config_info,\n\u001b[1;32m     28\u001b[0m     get_dataset_config_names,\n\u001b[1;32m     29\u001b[0m     get_dataset_default_config_name,\n\u001b[1;32m     30\u001b[0m     get_dataset_infos,\n\u001b[1;32m     31\u001b[0m     get_dataset_split_names,\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miterable_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IterableColumn, IterableDataset\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset, load_dataset_builder, load_from_disk\n",
      "File \u001b[0;32m~/test_env/lib/python3.9/site-packages/datasets/inspect.py:26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstreaming_download_manager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StreamingDownloadManager\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DatasetInfo\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m     dataset_module_factory,\n\u001b[1;32m     28\u001b[0m     get_dataset_builder_class,\n\u001b[1;32m     29\u001b[0m     load_dataset_builder,\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_logger\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Version\n",
      "File \u001b[0;32m~/test_env/lib/python3.9/site-packages/datasets/load.py:67\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miterable_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IterableDataset\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnaming\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m camelcase_to_snakecase, snakecase_to_camelcase\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpackaged_modules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     68\u001b[0m     _EXTENSION_TO_MODULE,\n\u001b[1;32m     69\u001b[0m     _MODULE_TO_EXTENSIONS,\n\u001b[1;32m     70\u001b[0m     _MODULE_TO_METADATA_FILE_NAMES,\n\u001b[1;32m     71\u001b[0m     _PACKAGED_DATASETS_MODULES,\n\u001b[1;32m     72\u001b[0m )\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpackaged_modules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfolder_based_builder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfolder_based_builder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FolderBasedBuilder\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msplits\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Split\n",
      "File \u001b[0;32m~/test_env/lib/python3.9/site-packages/datasets/packaged_modules/__init__.py:7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Tuple\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m insecure_hashlib\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m arrow\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudiofolder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audiofolder\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cache\n",
      "File \u001b[0;32m~/test_env/lib/python3.9/site-packages/datasets/packaged_modules/arrow/arrow.py:11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtable\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m table_cast\n\u001b[0;32m---> 11\u001b[0m logger \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mArrowConfig\u001b[39;00m(datasets\u001b[38;5;241m.\u001b[39mBuilderConfig):\n\u001b[1;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"BuilderConfig for Arrow.\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'datasets' has no attribute 'utils' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset  \n",
    "from pruna.data.pruna_datamodule import PrunaDataModule  \n",
    "from pruna.data.utils import split_train_into_train_val_test  \n",
    "\n",
    "# Load and split dataset\n",
    "ds = load_dataset(\"data-is-better-together/open-image-preferences-v1-binarized\")[\"train\"]\n",
    "train_ds, val_ds, test_ds = split_train_into_train_val_test(ds, seed=42)\n",
    "\n",
    "# Initialize PrunaDataModule\n",
    "datamodule = PrunaDataModule.from_datasets(  \n",
    "    datasets=(train_ds, val_ds, test_ds),  \n",
    "    collate_fn=\"image_generation_collate\",  \n",
    "    collate_fn_args={\"img_size\": 512, \"output_format\": \"float\"}  \n",
    ")\n",
    "\n",
    "# Limit datasets to 5 samples each for quick testing\n",
    "datamodule.limit_datasets(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model\n",
    "\n",
    "Now that the model and dataset are set up, we can proceed to evaluate the model using the **Pruna Evaluation Agent**. This evaluation helps us measure the model’s current performance before optimization, providing a baseline for comparison. It assesses how well the model performs on the given dataset and generates relevant metrics that will guide us in understanding the impact of our optimization configurations later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiple distributions found for package optimum. Picked distribution: optimum\n",
      "WARNING:bitsandbytes.cextension:The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers and GPU quantization are unavailable.\n",
      "WARNING:opentelemetry.metrics._internal:Overriding of current MeterProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "from pruna import PrunaModel\n",
    "from pruna.data.pruna_datamodule import PrunaDataModule\n",
    "from pruna.evaluation.evaluation_agent import EvaluationAgent\n",
    "from pruna.evaluation.metrics import (\n",
    "    LatencyMetric,\n",
    "    TotalTimeMetric,\n",
    ")\n",
    "from pruna.evaluation.task import Task\n",
    "\n",
    "smashed_pipe = PrunaModel.from_hub(\"AINovice2005/Sana_600M_ControlNet_HED-smashed\")\n",
    "\n",
    "metrics = [\n",
    "    TotalTimeMetric(n_iterations=3, n_warmup_iterations=1),\n",
    "    LatencyMetric(n_iterations=3, n_warmup_iterations=1),\n",
    "]\n",
    "\n",
    "# Define the task and the evaluation agent\n",
    "task = Task(metrics, datamodule=datamodule, device=device)\n",
    "eval_agent = EvaluationAgent(task)\n",
    "\n",
    "\n",
    "# Evaluate smashed model and offload it to CPU\n",
    "smashed_pipe.move_to_device(device)\n",
    "smashed_model_results = eval_agent.evaluate(smashed_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradio Demo\n",
    "\n",
    "Once the model has been optimized, we can deploy the smashed model using **Gradio** to create an interactive demo. This allows anyone to test the model’s capabilities directly in their browser.\n",
    "\n",
    "In this section, we will:\n",
    "\n",
    "* Show how to deploy the optimized model on the Hugging Face Hub with a Gradio demo\n",
    "* Discuss considerations such as **handling queuing**, especially if multiple users access the demo simultaneously\n",
    "* Highlight best practices for integrating Gradio demos in your Hugging Face Space to ensure a smooth and responsive user experience\n",
    "\n",
    "Creating a Gradio demo not only showcases your optimized model effectively but also enables easy sharing and real-world testing by the community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiple distributions found for package optimum. Picked distribution: optimum\n",
      "WARNING:opentelemetry.metrics._internal:Overriding of current MeterProvider is not allowed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6468c1697d234010875d157eb8c72416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Using best available device: 'cuda'\n",
      "WARNING - Argument cache_dir not found in config file. Skipping...\n",
      "/teamspace/studios/this_studio/.venv/lib/python3.10/site-packages/diffusers/configuration_utils.py:248: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a model, please use <class 'diffusers.models.transformers.sana_transformer.SanaTransformer2DModel'>.load_config(...) followed by <class 'diffusers.models.transformers.sana_transformer.SanaTransformer2DModel'>.from_config(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.\n",
      "  deprecate(\"config-passed-as-path\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
      "100%|██████████| 231/231 [00:00<00:00, 59364.27it/s]\n",
      "100%|██████████| 230/230 [00:00<00:00, 7521.71it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5dd4b952897485d8f8b493d23ab915d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0ffb436674441c88cbea19d63f887c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Could not move model to device: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.\n",
      "/teamspace/studios/this_studio/.venv/lib/python3.10/site-packages/gradio/interface.py:419: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from pruna import PrunaModel\n",
    "\n",
    "\n",
    "# ✅ Load PrunaModel\n",
    "model = PrunaModel.from_hub(\"AINovice2005/Sana_600M_ControlNet_HED-smashed\")\n",
    "\n",
    "# ✅ Inference function\n",
    "def generate_image(prompt):\n",
    "    result = pipe(prompt, num_inference_steps=25, guidance_scale=7.5)\n",
    "    return result.images[0]\n",
    "\n",
    "# ✅ Create Gradio interface with queueing enabled\n",
    "demo = gr.Interface(\n",
    "    fn=generate_image,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"Enter your prompt here...\", label=\"Prompt\"),\n",
    "    outputs=gr.Image(type=\"pil\"),\n",
    "    title=\"Sana Smashed Text-to-Image Demo\",\n",
    "    description=\"Generate high-quality images using the smashed Sana diffusion model optimized with Pruna.\",\n",
    "    allow_flagging=\"never\"\n",
    ")\n",
    "\n",
    "# ✅ Enable queueing to handle multiple users\n",
    "demo.queue()\n",
    "\n",
    "# ✅ Launch the app\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
