{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing and Deploying AI Models with Pruna and Hugging Face\n",
    "\n",
    "`Goal`: Create an end-to-end tutorial to optimize the black-forest-labs/FLUX.1-dev model using Pruna and deploy it on the Hugging Face Hub.\n",
    "\n",
    "`Model`:[black-forest-labs/FLUX.1-dev](https://huggingface.co/black-forest-labs/FLUX.1-dev)\n",
    "\n",
    "`Dataset`: [data-is-better-together/open-image-preferences-v1-binarized](https://huggingface.co/datasets/data-is-better-together/open-image-preferences-v1-binarized)\n",
    "\n",
    "To complete the tutorial, you need to install the pruna SDK along with a few third-party libraries via pip. It is recommended to run this notebook in a new virtual environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pruna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install datasets huggingface_hub gradio diffusers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to login on the Hugging Face Hub for using the model weights. Run the cell below to do the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smash Configuration:\n",
    "\n",
    "In order to optimize the model, we need to define the methods which can help to improve the performance. To know more, you can view the [SmashConfig guide](https://docs.pruna.ai/en/stable/docs_pruna/user_manual/configure.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import FluxPipeline\n",
    "from pruna import smash, SmashConfig\n",
    "\n",
    "# Load the pipeline\n",
    "pipe = FluxPipeline.from_pretrained(\"black-forest-labs/FLUX.1-schnell\", torch_dtype=torch.bfloat16)\n",
    "pipe.enable_model_cpu_offload()\n",
    "\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "# Configure Pruna smash\n",
    "smash_config = SmashConfig()\n",
    "smash_config[\"compiler\"] = \"torch_compile\"\n",
    "smash_config[\"quantizer\"] = \"hqq_diffusers\" \n",
    "smash_config[\"cacher\"]=\"deepcache\" \n",
    "\n",
    "# Smash the pipeline\n",
    "smashed_pipe = smash(model=pipe, smash_config=smash_config)\n",
    "\n",
    "# Save the model\n",
    "smashed_model.save_pretrained(\"saved_models/FLUX.1-schnell-smashed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the model to HuggingFace Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, Repository\n",
    "\n",
    "# Load the model\n",
    "smashed_model = PrunaModel.from_pretrained(\"saved_models/FLUX.1-schnell-smashed\")\n",
    "\n",
    "\n",
    "\n",
    "api = HfApi()\n",
    "repo_url = api.create_repo(\"FLUX.1-schnell-smashed\", exist_ok=True, private=False)\n",
    "\n",
    "repo = Repository(local_dir=\"FLUX.1-schnell-smashed\", clone_from=repo_url)\n",
    "\n",
    "repo.push_to_hub(commit_message=\"add FLUX.1-schnell-smashed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load the binarized Open Image Preferences prompts\n",
    "ds = load_dataset(\"data-is-better-together/open-image-preferences-v1-binarized\", split=\"train\")\n",
    "\n",
    "# preview 10 examples\n",
    "for example in ds.select(range(10)):\n",
    "    print(example[\"prompt\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from diffusers import AutoPipelineForText2Image\n",
    "from pruna.engine.pruna_model import PrunaModel\n",
    "from pruna.evaluation.evaluation_agent import EvaluationAgent\n",
    "from pruna.evaluation.task import Task\n",
    "\n",
    "# Step 1: Load the dataset and select a subset (e.g., 10 examples)\n",
    "dataset = load_dataset(\"data-is-better-together/open-image-preferences-v1-binarized\", split=\"train\")\n",
    "selected_dataset = dataset.select(range(10))  # Use first 10 examples only\n",
    "\n",
    "# Step 2: Load the Flux Dev model\n",
    "pipe = AutoPipelineForText2Image.from_pretrained(\"black-forest-labs/FLUX.1-dev\")\n",
    "pipe.set_progress_bar_config(disable=True)\n",
    "model = PrunaModel(pipe)\n",
    "\n",
    "# Step 3: Define the evaluation task using the selected dataset\n",
    "task = Task(\n",
    "    task_type=\"image_generation\",\n",
    "    dataset=selected_dataset,\n",
    "    prompt_column=\"prompt\",\n",
    "    reference_column=\"image\",       # Ensure the column contains reference images or ground truth\n",
    "    preference_column=\"preference\"  # Used for preference-based evaluation\n",
    ")\n",
    "\n",
    "# Step 4: Run evaluation\n",
    "agent = EvaluationAgent(model=model, task=task)\n",
    "results = agent.evaluate(metrics=[\"cmmd\"])\n",
    "\n",
    "# Step 5: Print results\n",
    "print(\"Evaluation Results on Selected Subset:\")\n",
    "for metric, score in results.items():\n",
    "    print(f\"{metric}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradio Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from diffusers import DiffusionPipeline\n",
    "\n",
    "# Load the HiDream model\n",
    "pipe = DiffusionPipeline.from_pretrained(\"FLUX.1-schnell-smashed\")\n",
    "\n",
    "# Define the generation function\n",
    "def generate(prompt):\n",
    "    return pipe(prompt).images[0]\n",
    "\n",
    "# Create the Gradio interface\n",
    "gr.Interface(fn=generate, inputs=\"text\", outputs=\"image\").launch()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
