{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing and Deploying AI Models with Pruna and Hugging Face\n",
    "\n",
    "`Goal`: Create an end-to-end tutorial to optimize the black-forest-labs/FLUX.1-dev model using Pruna and deploy it on the Hugging Face Hub.\n",
    "\n",
    "`Model`:[black-forest-labs/FLUX.1-dev](https://huggingface.co/black-forest-labs/FLUX.1-dev)\n",
    "\n",
    "`Dataset`: [data-is-better-together/open-image-preferences-v1-binarized](https://huggingface.co/datasets/data-is-better-together/open-image-preferences-v1-binarized)\n",
    "\n",
    "To complete the tutorial, you need to install the pruna SDK along with a few third-party libraries via pip. It is recommended to run this notebook in a new virtual environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pruna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install datasets huggingface_hub gradio diffusers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to login on the Hugging Face Hub for using the model weights. Run the cell below to do the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c340e3bef4d47329fba11ba4e1b422a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smash Configuration:\n",
    "\n",
    "In order to optimize the model, we need to define the methods which can help to improve the performance. To know more, you can view the [SmashConfig guide](https://docs.pruna.ai/en/stable/docs_pruna/user_manual/configure.html).\n",
    "\n",
    "We will select a quantizer to lower memory requirements and cacher for intermediate results of computations to speed up subsequent operations.\n",
    "\n",
    "We will also upload the smashed model to the Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import FluxPipeline\n",
    "from pruna import smash, SmashConfig\n",
    "\n",
    "# 1. Load the original FLUX pipeline\n",
    "pipe = FluxPipeline.from_pretrained(\n",
    "    \"black-forest-labs/FLUX.1-schnell\", torch_dtype=torch.bfloat16\n",
    ").to(\"cuda\")\n",
    "\n",
    "# 2. Configure Pruna smash\n",
    "smash_config = SmashConfig()\n",
    "smash_config[\"quantizer\"] = \"hqq_diffusers\" \n",
    "smash_config[\"cacher\"] = \"pab\"\n",
    "\n",
    "# 3. Smash the model\n",
    "smashed_pipe = smash(model=pipe, smash_config=smash_config)\n",
    "\n",
    "# 4. Push smashed pipeline to the Hub\n",
    "smashed_pipe.save_to_hub(\"AINovice2005/smashed-FLUX.1-schnell-pruna\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load the binarized Open Image Preferences prompts\n",
    "ds = load_dataset(\"data-is-better-together/open-image-preferences-v1-binarized\", split=\"train\")\n",
    "\n",
    "# preview 10 examples\n",
    "for example in ds.select(range(50)):\n",
    "    print(example[\"prompt\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from diffusers import AutoPipelineForText2Image\n",
    "from pruna.engine.pruna_model import PrunaModel\n",
    "from pruna.evaluation.evaluation_agent import EvaluationAgent\n",
    "from pruna.evaluation.task import Task\n",
    "\n",
    "# 1. Load only the first 50 examples from the dataset\n",
    "hf_dataset = load_dataset(\n",
    "    \"data-is-better-together/open-image-preferences-v1-binarized\",\n",
    "    split=\"train[:50]\"\n",
    ")\n",
    "\n",
    "# 2. Custom PyTorch dataset to extract prompts from the 'chosen' field\n",
    "class OpenImagesChosenPromptDataset(Dataset):\n",
    "    def __init__(self, hf_dataset):\n",
    "        self.samples = hf_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\"prompt\": self.samples[idx][\"chosen\"]}\n",
    "\n",
    "eval_dataset = OpenImagesChosenPromptDataset(hf_dataset)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=1)\n",
    "\n",
    "# 3. Load the Pruna-wrapped model from local path\n",
    "loaded_model = PrunaModel.from_hub(\n",
    "    \"AINovice2005/smashed-FLUX.1-schnell-pruna\",  # Path to your saved model directory\n",
    ").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 4. Create the EvaluationAgent with task defined\n",
    "agent = EvaluationAgent(\n",
    "    pipeline=loaded_model,\n",
    "    task=Task.TEXT2IMAGE,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "\n",
    "# 5. Run evaluation with CLIP score\n",
    "results = agent.evaluate(\n",
    "    dataloader=eval_dataloader,\n",
    "    num_batches=50,\n",
    "    metrics=[\"clip_score\"],\n",
    "    save_path=\"./eval_results.json\"\n",
    ")\n",
    "\n",
    "# 6. Print results\n",
    "print(\"ðŸ“Š Evaluation Results:\")\n",
    "for metric, score in results.items():\n",
    "    print(f\"{metric}: {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradio Demo\n",
    "\n",
    "Now, we will deploy the smashed model on gradio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from diffusers import DiffusionPipeline\n",
    "\n",
    "# Load the HiDream model\n",
    "pipe = DiffusionPipeline.from_pretrained(\"FLUX.1-schnell-smashed\")\n",
    "\n",
    "# Define the generation function\n",
    "def generate(prompt):\n",
    "    return pipe(prompt).images[0]\n",
    "\n",
    "# Create the Gradio interface\n",
    "gr.Interface(fn=generate, inputs=\"text\", outputs=\"image\").launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
