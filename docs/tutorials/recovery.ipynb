{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recovering Quality after Quantizing Models to 4 Bits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/PrunaAI/pruna/blob/v|version|/docs/tutorials/recovery.ipynb\">\n",
    "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "\n",
    "This tutorial demonstrates how to use the ``pruna`` package to use our experimental \"recovery\" feature to recover the model quality after quantization. This option allows you to push quantization or other compression techniques to the limit without compromising quality.\n",
    "\n",
    "We will use :doc:`PERP </compression>` on the Sana model as an example, but you can also use Stable Diffusion and Flux models depending on your device. Any execution times given below are measured on a L40S GPU.\n",
    "\n",
    "Note that recovery is available in the ``pruna`` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading the Sana Model\n",
    "\n",
    "First, load the Sana model, and generate an image for quality reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import SanaPipeline\n",
    "\n",
    "pipe = SanaPipeline.from_pretrained(\n",
    "    \"Efficient-Large-Model/Sana_1600M_1024px_BF16_diffusers\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ").to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate an image to have a reference for quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A crow walking along a river near a foggy cliff, with cute yellow ducklings following it in a line, at sunset.\"\n",
    "pipe(prompt).images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initializing the SmashConfig"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Next, initialize the SmashConfig. We'll use :doc:`bitsandbytes' quantization </compression>` to 4 bits, and recover quality by finetuning with PERP on a text-to-image dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pruna import SmashConfig\n",
    "\n",
    "smash_config = SmashConfig({\n",
    "    # Quantize the model to 4-bits\n",
    "    \"diffusers_int8\": {\n",
    "        \"weight_bits\": 4\n",
    "    },\n",
    "    # Recover, allowing you to push quantization to lower bit rates without compromising quality\n",
    "    \"text_to_image_perp\": {\n",
    "        # you can increase or reduce 'batch_size' depending on your GPU, or use 'gradient_accumulation_steps' with it\n",
    "        \"batch_size\": 8,\n",
    "        \"num_epochs\": 4,\n",
    "        \"validate_every_n_epoch\": 0.5 # run validation every half epoch\n",
    "    }\n",
    "})\n",
    "# Attach a text-to-image dataset, used for recovery\n",
    "smash_config.add_data(\"COCO\")\n",
    "smash_config.data.limit_datasets((256, 64, 1))  # training on 256 samples and validating on 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Smashing the Model\n",
    "\n",
    "Now, smash the model. This takes about 9 minutes on an L40S GPU, but it depends on how many samples are used for recovery.\n",
    "Recovery logging is handled though __Weights & Biases__, make sure you have it installed and set up in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pruna import smash\n",
    "\n",
    "smashed_model = smash(\n",
    "    model=pipe,\n",
    "    smash_config=smash_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Running the Model\n",
    "Finally, we run the model which has been quantized and recovered. It has a lower memory footprint than the original because of the quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smashed_model(prompt).images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap up"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Congratulations! You have successfully recovered quality on your compressed Sana model. You can now use the ``pruna`` package to its limit by using aggressive compression alongside recovery. The only parts you should modify are steps 1 and 4 to fit your use case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prunatree",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
