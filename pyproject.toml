[tool.ruff]
exclude = ["test_*.py"]
line-length = 121

[tool.ruff.lint]
ignore = ["ANN002", "ANN003", "ANN401", "C901", "D100", "D104", "D401", "D406", "C408"]
select = ["A", "C", "CPY", "D", "E", "ERA", "F", "FIX", "I", "N", "SIM", "T20", "W", "FA"]
preview = true  # enable preview features for copyright checking

[tool.ruff.lint.per-file-ignores]
"*.ipynb" = ["ERA", "CPY", "T"]  # commented out code is intended for tutorials
"tests/*" = ["T20", "CPY"]  # print statements are intended for tests
"docs/*" = ["CPY"]

[tool.ruff.lint.pydocstyle]
convention = "numpy"

[tool.ruff.lint.flake8-copyright]
author = "- Pruna AI GmbH"

[tool.mypy]
ignore_missing_imports = true

[tool.poetry]
name = "pruna"
version = "0.2.5"
description = "Smash your AI models"
authors = ["Pruna AI <hello@pruna.ai>"]
license = "All Rights Reserved"

# **Include only .so files in the built distributions**
include = ["**/*.so"]

# **Exclude specific files or directories from the built distributions**
exclude = [
    "tests*",
    "docs*",
]

[[tool.poetry.source]]
name = "pruna"
url = "https://prunaai.pythonanywhere.com/"
priority = "supplemental"

[tool.poetry.dependencies]
python = ">=3.9,<3.13"
wget = "*"
torch = "2.7.0"
torchvision = "0.22.0"
torchmetrics = { version = "*", extras = ["image"] }
accelerate = ">0.28.0"
requests = ">=2.31.0"
transformers = "*"
pillow = ">=9.5.0"
pytorch-lightning = "*"
huggingface-hub = { version = ">=0.30.0", extras = ["hf-xet"] }
datasets = ">=0.34"
jsonschema = "*"
numpy = ">=1.24.4"
setuptools = "*"
packaging = "*"
diffusers = ">=0.21.4"
platformdirs = "*"
torch_pruning = "*"
python-dotenv = "*"
ConfigSpace = ">=1.2.1"
cython = "*"  # Consider removing if Cython is only needed for building
lago-python-client = "*"
sentencepiece = "*"
blobfile = "*"
librosa = "*"
openvino = "*"
soundfile = "*"
ipywidgets = ">=8.1.5"
DeepCache = "*"
colorama = "*"
protobuf = "*"
peft = "*"
optuna = "*"
trl = "*"
opentelemetry-api = ">=1.30.0"
opentelemetry-sdk = ">=1.30.0"
opentelemetry-exporter-otlp = ">=1.29.0"
codecarbon = "*"
pynvml = "*"
thop = "*"
timm = "*"
# bitsandbytes is not supported on macOS arm64
bitsandbytes = { version = "*", markers = "sys_platform != 'darwin' or platform_machine != 'arm64'" }
optimum-quanto = ">=0.2.5"
optimum = "*"
ctranslate2 = "==4.6.0"
whisper-s2t = "==1.3.0"
hqq = "<0.2.7" # pinned to 0.2.6 to avoid re-loading model bug introduced in 0.2.7
torchao = "*"
llmcompressor = "*"
# Added Optional Dependencies from Extras
ruff = { version = "*", optional = true, markers = "extra == 'dev' or extra == 'tests'" }
jupyterlab = { version = "*", optional = true, markers = "extra == 'dev' or extra == 'tests'" }
notebook = { version = "*", optional = true, markers = "extra == 'dev'" }
pre-commit = { version = "*", optional = true, markers = "extra == 'dev'" }
build = { version = "*", optional = true, markers = "extra == 'dev'" }
twine = { version = "*", optional = true, markers = "extra == 'dev'" }
pyc-wheel = { version = "*", optional = true, markers = "extra == 'dev'" }
pytest-cov = { version = "*", optional = true, markers = "extra == 'tests'" }
coverage = { version = "*", optional = true, markers = "extra == 'tests'" }
pytest = { version = "*", optional = true, markers = "extra == 'tests'" }
docutils = { version = "*", optional = true, markers = "extra == 'tests'" }
xformers = { version = "==0.0.30", optional = true, markers = "extra == 'stable-fast' or extra == 'full'" }
stable-fast-pruna = { version = "1.0.7", optional = true, markers = "extra == 'stable-fast' or extra == 'full'" }
numpydoc-validation = { version = "*", optional = true, markers = "extra == 'dev' or extra == 'tests'" }
mypy = { version = "*", optional = true, markers = "extra == 'tests'" }
types-PyYAML = { version = "*", optional = true, markers = "extra == 'tests'" }
# gptqmodel with version 4.0.0.dev0+cu126torch2.7 is not supported on macOS arm64
gptqmodel = [
    { version = "==4.0.0.dev0+cu126torch2.7", optional = true, markers = "extra == 'gptq' and (sys_platform != 'darwin' or platform_machine != 'arm64')" },
    { version = "*", optional = true, markers = "extra == 'gptq' and (sys_platform == 'darwin' and platform_machine == 'arm64')" }
]
logbar = { version = "*", optional = true, markers = "extra == 'gptq'" }
tokenicer = { version = "*", optional = true, markers = "extra == 'gptq'" }
threadpoolctl = { version = "*", optional = true, markers = "extra == 'gptq'" }
device-smi = { version = "*", optional = true, markers = "extra == 'gptq'" }
random-word = { version = "*", optional = true, markers = "extra == 'gptq'" }

[tool.poetry.extras]
stable-fast = [
    "xformers",
    "stable-fast-pruna",
]
# Note: You must first install the base package with ``pip install pruna`` before installing the GPTQ extension with ``pip install pruna[gptq]``
gptq = [
    "gptqmodel",
    "logbar",
    "tokenicer",
    "threadpoolctl",
    "device-smi",
    "random-word",
]
full = [
    "xformers",
    "stable-fast-pruna",
]
dev = [
    "jupyterlab",
    "notebook",
    "pre-commit",
    "build",
    "twine",
    "pyc-wheel",
    "ruff",
    "numpydoc-validation",
]
tests = [
    "pytest",
    "pytest-cov",
    "coverage",
    "docutils",
    "jupyterlab",
    "numpydoc-validation",
    "mypy",
    "ruff",
    "types-PyYAML",
]
cpu = []

[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"

[tool.setuptools]
package-dir = {"" = "pruna"}

[tool.setuptools.packages.find]
where = ["pruna"]
include = ["pruna"]
exclude = ["openai", "docker", "saved_model"]