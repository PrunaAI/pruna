# Copyright 2025 - Pruna AI GmbH. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import annotations

from typing import Any, List

import numpy as np
import torch
from easydict import EasyDict
from vbench.dynamic_degree import DynamicDegree
from vbench.third_party.RAFT.core.utils_core.utils import InputPadder
from vbench.utils import init_submodules

from pruna.engine.utils import set_to_best_available_device
from pruna.evaluation.metrics.metric_stateful import StatefulMetric
from pruna.evaluation.metrics.registry import MetricRegistry
from pruna.evaluation.metrics.result import MetricResult
from pruna.evaluation.metrics.utils import PAIRWISE, SINGLE, get_call_type_for_single_metric, metric_data_processor
from pruna.evaluation.metrics.vbench_utils import VBenchMixin
from pruna.logging.logger import pruna_logger

METRIC_VBENCH_DYNAMIC_DEGREE = "dynamic_degree"


class PrunaDynamicDegree(DynamicDegree):
    """Helper class to compute Dynamic Degree score for a given video."""

    def infer(self, frames: torch.Tensor, interval: int) -> bool:
        """
        Compute Dynamic Degree score for a given video.

        Uses the RAFT Model for given video frames.

        Parameters
        ----------
        frames: torch.Tensor
            The video frames to compute the Dynamic Degree score for.
        interval: int
            The interval to skip frames. It's possible for each consecutive frame to not have extreme motion,
            even though the video itself contains large dynamic changes.
            Therefore it's important to set the inteval to skip frames correctly.

        Returns
        -------
        bool
            Whether the video contains large motions.
        """
        frames = [fr.unsqueeze(0) for fr in frames]

        frames = self.extract_frame(frames, interval=max(1, interval))
        self.set_params(frame=frames[0], count=len(frames))

        static_score = []
        for image1, image2 in zip(frames[:-1], frames[1:]):
            padder = InputPadder(image1.shape)
            image1, image2 = padder.pad(image1, image2)
            # 20 iterations as the original DynamicDegree implementation.
            _, flow_up = self.model(image1, image2, iters=20, test_mode=True)
            max_rad = self.get_score(image1, flow_up)
            static_score.append(max_rad)
        whether_move = self.check_move(static_score)
        return whether_move


@MetricRegistry.register(METRIC_VBENCH_DYNAMIC_DEGREE)
class VBenchDynamicDegree(StatefulMetric, VBenchMixin):
    """
    Dynamic Degree Dimension from the Vbench video benchmark suite.

    It measures the degree of dynamics (i.e. whether it contains large motions) generated by the model.

    This is important since a completely static video can score well
    in temporal quality metrics but is not actually useful.

    Parameters
    ----------
    *args : Any
        The arguments to be passed to the DynamicDegree class.
    device : str | None, optional
        The device to be used, e.g., 'cuda' or 'cpu'. Default is None.
        If None, the best available device will be used.
    call_type : str, default="y"
        The call type to be used, e.g., 'y' or 'y_gt'. Default is "y".
    interval : int, default=3
        The interval to be used to extract frames from the video.
        The default Vbench dimension loads videos from file and preprocesses them to have 8 frames per second.
        For instance, if the video is 24fps, Vbench will only get every 3rd frame.
        Here, we deal directly with the model outputs, so we initialize the interval to be 3,
        which is a reasonable skip interval.
        Feel free to change this to your needs.
    **kwargs : Any
        The keyword arguments to be passed to the DynamicDegree class.
    """

    metric_name: str = METRIC_VBENCH_DYNAMIC_DEGREE
    default_call_type: str = "y"  # We just need the outputs
    higher_is_better: bool = True
    # https://github.com/Vchitect/VBench/blob/dc62783c0fb4fd333249c0b669027fe102696682/evaluate.py#L111
    # explicitly sets the device to cuda. We respect this here.
    runs_on: List[str] = ["cuda"]
    modality: List[str] = ["video"]
    # state
    scores: List[bool]

    def __init__(
        self,
        *args: Any,
        device: str | None = None,
        call_type: str = SINGLE,
        interval: int = 3,
        **kwargs: Any,
    ) -> None:
        super().__init__(*args, **kwargs)

        if device is not None and str(device).split(":")[0] not in self.runs_on:
            pruna_logger.error(f"Unsupported device {device}; supported: {self.runs_on}")
            raise ValueError()

        if call_type == PAIRWISE:
            # VBench itself does not support pairwise.
            # We can work on this in the future.
            pruna_logger.error("VBench does not support pairwise metrics. Please use single mode.")
            raise ValueError()

        self.interval = interval
        submodules_dict = init_submodules([METRIC_VBENCH_DYNAMIC_DEGREE])
        model_path = submodules_dict[METRIC_VBENCH_DYNAMIC_DEGREE]["model"]

        self.device = set_to_best_available_device(device)
        self.call_type = get_call_type_for_single_metric(call_type, self.default_call_type)
        #  RAFT models expect arguments to be passed as an object with attributes.
        #  So we need to convert the arguments to an EasyDict.
        args_new = EasyDict({"model": model_path, "small": False, "mixed_precision": False, "alternate_corr": False})
        self.DynamicDegree = PrunaDynamicDegree(args_new, self.device)
        self.add_state("scores", [])

    @torch.no_grad()
    def update(self, x: List[str], gt: Any, outputs: Any) -> None:
        """
        Calculate the dynamic degree score for the given video.

        Then passed to the RAFT model to calculate the dynamic degree score.

        Each video is ranked as a 1 or 0 based on whether it contains large motions.
        The final score is the mean of the scores for all videos.

        Parameters
        ----------
        x : List[str]
            The list of input videos.
        gt : Any
            The ground truth videos.
        outputs : Any
            The generated videos. Should be a tensor of shape (T, C, H, W) or (B, T, C, H, W).
            where B is the batch size, T is the number of frames, C is the number of channels, H is the height,
            and W is the width.
        """
        outputs = metric_data_processor(x, gt, outputs, self.call_type, device=self.device)
        videos = super().validate_batch(outputs[0])

        for video in videos:
            score = self.DynamicDegree.infer(video, self.interval)
            self.scores.append(score)

    def compute(self) -> MetricResult:
        """
        Calculate the final dynamic degree score.

        The final score is the mean of the scores for all videos.

        Returns
        -------
        MetricResult
            The dynamic degree score.
        """
        final_score = np.mean(self.scores)
        return MetricResult(name=self.metric_name, params=self.__dict__, result=final_score)

    def reset(self) -> None:
        """Reset the state variables for the metric."""
        super().reset()
        self.scores.clear()
